# ã€OpenCVã€‘åŒç›®ç›¸æœºè®¡ç®—æ·±åº¦å›¾å’Œç‚¹äº‘

**åŒç›®ç›¸æœºè®¡ç®—æ·±åº¦å›¾çš„åŸºæœ¬åŸç†æ˜¯é€šè¿‡ä¸¤å°ç›¸æœºä»ä¸åŒè§’åº¦æ‹æ‘„åŒä¸€åœºæ™¯ï¼Œç„¶ååˆ©ç”¨è§†å·®æ¥è®¡ç®—ç‰©ä½“çš„è·ç¦»ã€‚æœ¬æ–‡çš„Pythonå®ç°ç¤ºä¾‹ï¼Œä½¿ç”¨OpenCVåº“æ¥å¤„ç†å›¾åƒå’Œè®¡ç®—æ·±åº¦å›¾ã€‚**
## 1ã€æ•°æ®é›†ä»‹ç»
[`Mobile stereo datasets`](https://vision.middlebury.edu/stereo/data/scenes2021/)ç”±Pan Guanghanã€Sun Tianshengã€Toby Weedå’ŒDaniel Scharsteinåœ¨2019-2021å¹´æœŸé—´åˆ›å»ºçš„ï¼Œä½¿ç”¨äº†Roger Daiã€Kyle Meredithã€Tommaso Monacoã€Nick Mosierå’ŒDaniel Scharsteinåœ¨2017-2018å¹´æœŸé—´å¼€å‘çš„ç»“æ„åŒ–å…‰é‡‡é›†ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨å®‰è£…åœ¨UR5æœºæ¢°è‡‚ä¸Šçš„ç§»åŠ¨è®¾å¤‡ï¼ˆè‹¹æœiPod touch 6Gï¼‰ï¼›åœ°åŸºçœŸå·®æ˜¯ä½¿ç”¨[5]ä¸­æè¿°çš„ç»“æ„åŒ–ç…§æ˜ç®¡é“çš„ä¸€ä¸ªå­é›†æ¥è®¡ç®—çš„ã€‚è¿™äº›æ•°æ®é›†åŒ…æ‹¬11ä¸ªåœºæ™¯ï¼Œåœ¨è®¸å¤šä¸åŒçš„ç…§æ˜æ¡ä»¶å’Œæ›å…‰ï¼ˆåŒ…æ‹¬é—ªå…‰ç¯å’Œç§»åŠ¨è®¾å¤‡çš„â€œç«ç‚¬â€ç…§æ˜ï¼‰ä¸‹ï¼Œä»1-3ä¸ªä¸åŒçš„è§‚çœ‹æ–¹å‘æ‹æ‘„ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](access/012.png)


**æ•°æ®é›†åŸºæœ¬æè¿°ï¼š**
```
Dataset description
Each dataset consists of 2 views taken under several different illuminations and exposures. The files are organized as follows:
SCENE{1,2,3}/                  -- scene imaged from 1-3 viewing directions
  ambient/                     -- directory of all input views under ambient lighting
    {F,L,T}{0,1,...}/          -- different lighting conditions (F=flash, L=lighting, T=torch)
      im0e{0,1,2,...}.png      -- left view under different exposures
      im1e{0,1,2,...}.png      -- right view under different exposures
  calib.txt                    -- calibration information
  im{0,1}.png                  -- default left and right view (typically ambient/L0/im{0,1}e2.png)
  disp{0,1}.pfm                -- left and right GT disparities
Zip files containing the above files can be downloaded here. "all.zip" contains all 24 scenes (image pair, disparities, calibration file), but not the ambient subdirectories. The latter are available in separate zip files.

Calibration file format
Here is a sample calib.txt file:
cam0=[1758.23 0 953.34; 0 1758.23 552.29; 0 0 1]
cam1=[1758.23 0 953.34; 0 1758.23 552.29; 0 0 1]
doffs=0
baseline=111.53
width=1920
height=1080
ndisp=290
isint=0
vmin=75
vmax=262
Explanation:

cam0,1:        camera matrices for the rectified views, in the form [f 0 cx; 0 f cy; 0 0 1], where
  f:           focal length in pixels
  cx, cy:      principal point

doffs:         x-difference of principal points, doffs = cx1 - cx0 (here always == 0)

baseline:      camera baseline in mm

width, height: image size

ndisp:         a conservative bound on the number of disparity levels;
               the stereo algorithm MAY utilize this bound and search from d = 0 .. ndisp-1

vmin, vmax:    a tight bound on minimum and maximum disparities, used for color visualization;
               the stereo algorithm MAY NOT utilize this information
To convert from the floating-point disparity value d [pixels] in the .pfm file to depth Z [mm] the following equation can be used:
Z = baseline * f / (d + doffs)
Note that the image viewer "sv" and mesh viewer "plyv" provided by our software cvkit can read the calib.txt files and provide this conversion automatically when viewing .pfm disparity maps as 3D meshes.
```
---
  - å¦‚æœä½¿ç”¨è‡ªå·±çš„åŒç›®ç›¸æœºï¼Œåˆ™éœ€è¦çŸ¥é“ç›¸æœºä¸¤ä¸ªæ‘„åƒå¤´çš„å†…å‚çŸ©é˜µ`cam0,1`ã€åŸºçº¿`baseline `
 
---


## 2ã€Pythonä»£ç 
ä»£ç ä½¿ç”¨çš„åŒç›®å›¾åƒæ•°æ®æ˜¯`chess2`
```python
import cv2
import numpy as np
import time
import matplotlib.pyplot as plt

def load_images(left_path, right_path):
    left_image = cv2.imread(left_path, 0)
    right_image = cv2.imread(right_path, 0)
    return left_image, right_image

#
def compute_disparity_map(left_image, right_image, cam0, cam1, doffs, ndisp, vmin, vmax, block_size=15):
    stereo = cv2.StereoSGBM_create(
        minDisparity=vmin,  # è§†å·®ä»0å¼€å§‹
        numDisparities=ndisp,  # è§†å·®èŒƒå›´æ•°é‡ï¼Œå¿…é¡»æ˜¯16çš„å€æ•°
        blockSize=block_size,  # åŒ¹é…å—çš„å¤§å°ï¼Œå¥‡æ•°
        P1=8 * 3 * block_size ** 2,  # å¹³æ»‘æƒ©ç½šé¡¹ï¼ˆç¬¬ä¸€çº§ï¼‰
        P2=32 * 3 * block_size ** 2,  # å¹³æ»‘æƒ©ç½šé¡¹ï¼ˆç¬¬äºŒçº§ï¼‰ï¼Œé€šå¸¸æ˜¯P1çš„4å€
        disp12MaxDiff=1,  # å·¦å³è§†å·®æ£€æŸ¥çš„æœ€å¤§å…è®¸å·®å¼‚
        uniquenessRatio=10,  # å”¯ä¸€æ€§æ¯”ç‡é˜ˆå€¼
        speckleWindowSize=100,  # æ–‘ç‚¹æ»¤æ³¢å™¨çª—å£å¤§å°
        speckleRange=32  # æ–‘ç‚¹æ»¤æ³¢å™¨æœ€å¤§å®¹è®¸å·®å¼‚
    )
    disparity_map = stereo.compute(left_image, right_image).astype(np.float32) / 16.0
    return disparity_map

# è½¬æˆæ·±åº¦å›¾
def convert_disparity_to_depth(disparity_map, focal_length_px, baseline_mm):
    # é¿å…é™¤ä»¥é›¶çš„æƒ…å†µ
    depth_map = (focal_length_px * baseline_mm) / disparity_map
    depth_map[disparity_map == 0] = 0  # è®¾ç½®æ— æ•ˆåŒºåŸŸçš„æ·±åº¦ä¸º0
    return depth_map

# è¿‡æ»¤æœ€è¿œå¹³é¢
def filter_far_plane(depth_map, max_distance=1500):  
    depth_map[depth_map > max_distance] = 0
    return depth_map

#ç”Ÿæˆæ™®é€šç‚¹äº‘
def generate_point_cloud(depth_map, cam0, cx, cy):
    fx = cam0[0, 0]
    fy = cam0[1, 1]

    height, width = depth_map.shape

    # åˆ›å»ºç½‘æ ¼
    u, v = np.meshgrid(np.arange(width), np.arange(height))

    # è®¡ç®— x, y, z åæ ‡
    z = depth_map
    x = (u - cx) * z / fx
    y = (v - cy) * z / fy

    # å°†åæ ‡å †å æˆç‚¹äº‘æ•°ç»„
    point_cloud = np.stack((x, y, z), axis=-1)

    # è¿‡æ»¤æ‰æ— æ•ˆç‚¹ï¼ˆæ·±åº¦å€¼ä¸º 0 çš„ç‚¹ï¼‰
    valid_mask = z > 0
    point_cloud = point_cloud[valid_mask]

    return point_cloud

#ç”Ÿæˆå½©è‰²ç‚¹äº‘
def generate_colored_point_cloud(depth_map, cam0, cx, cy):  
    fx = cam0[0, 0]
    fy = cam0[1, 1]

    height, width = depth_map.shape

    # åˆ›å»ºç½‘æ ¼
    u, v = np.meshgrid(np.arange(width), np.arange(height))

    # è®¡ç®—x, y, zåæ ‡
    x = (u - cx) * depth_map / fx
    y = (v - cy) * depth_map / fy
    z = depth_map

    # å°†åæ ‡å †å æˆç‚¹äº‘æ•°ç»„
    point_cloud = np.stack((x, y, z), axis=-1)

    # å½’ä¸€åŒ–æ·±åº¦å€¼
    valid_mask = depth_map > 0
    normalized_depth = np.zeros_like(depth_map)
    if valid_mask.any():
        normalized_depth[valid_mask] = (depth_map[valid_mask] - np.min(depth_map[valid_mask])) / (np.max(depth_map[valid_mask]) - np.min(depth_map[valid_mask]))

    # ä½¿ç”¨jet colormapç”Ÿæˆé¢œè‰²
    colors = plt.cm.jet(normalized_depth)[:, :, :3]  # è·å–RGBé¢œè‰²ï¼Œå¿½ç•¥alphaé€šé“

    # å°†é¢œè‰²å€¼ä» [0, 1] è½¬æ¢ä¸º [0, 255] å¹¶è½¬æ¢ä¸º uint8 ç±»å‹
    colors = (colors * 255).astype(np.uint8)

    return point_cloud, colors

def save_point_cloud_to_txt(point_cloud, file_path):
    point_cloud = np.hstack([point_cloud.reshape(-1, 3)])
    np.savetxt(file_path, point_cloud, fmt='%f %f %f', header='x y z', comments='')

def save_point_cloud_to_txt_rgb(point_cloud, colors, file_path):
    points_with_colors = np.hstack([point_cloud.reshape(-1, 3), colors.reshape(-1, 3)])
    np.savetxt(file_path, points_with_colors, fmt='%f %f %f %f %f %f', header='x y z r g b', comments='')
    print(f"Colored point cloud saved to {file_path}")

if __name__ == "__main__":
    left_image_path = 'Stereo/data/chess2/ambient/L0/im0e3.png'  # æ›¿æ¢ä¸ºä½ çš„å·¦çœ¼å›¾åƒè·¯å¾„
    right_image_path = 'Stereo/data/chess2/ambient/L0/im1e3.png'  # æ›¿æ¢ä¸ºä½ çš„å³çœ¼å›¾åƒè·¯å¾„

    left_image, right_image = load_images(left_image_path, right_image_path)

    # åŒç›®ç›¸æœºå‚æ•°
    cam0 = np.array([[1758.23, 0, 872.36], [0, 1758.23, 552.32], [0, 0, 1]])
    cam1 = np.array([[1758.23, 0, 872.36], [0, 1758.23, 552.32], [0, 0, 1]])
    doffs = 0
    baseline_mm = 124.86
    width = 1920
    height = 1080
    ndisp = 310
    isint = 0
    vmin=90
    vmax=280

    # è®¡ç®—åƒç´ ç„¦è·
    fx = cam0[0, 0]
    fy = cam0[1, 1]
    cx = cam0[0, 2]
    cy = cam1[1, 2]


    start_time = time.time()

    disparity_map = compute_disparity_map(left_image, right_image, cam0, cam1, doffs, ndisp, vmin, vmax)
    depth_map = convert_disparity_to_depth(disparity_map, fx, baseline_mm)
    depth_map = filter_far_plane(depth_map, max_distance=depth_map.max()-1)  # è¿‡æ»¤æœ€è¿œçš„å¹³é¢
    # point_cloud = generate_point_cloud(depth_map, cam0, cx, cy)
    point_cloud, colors = generate_colored_point_cloud(depth_map, cam0, cx, cy)

    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Elapsed Time = {elapsed_time:.4f} seconds")

    #cv2.imshow('depth',depth_map)
    #cv2.waitKey(0)
    #cv2.imwrite('D:/dataset/depth.jpg',depth_map)

    # åˆ›å»º 1 è¡Œ 3 åˆ—çš„å­å›¾å¸ƒå±€
    plt.figure(figsize=(12, 4))
    # æ˜¾ç¤ºç¬¬å·¦å›¾
    plt.subplot(1, 3, 1)
    plt.imshow(cv2.imread(left_image_path)[:, :, ::-1] ) # åè½¬é€šé“é¡ºåº
    plt.title('left_image')
    plt.axis('off')
    # æ˜¾ç¤ºå³å›¾
    plt.subplot(1, 3, 2)
    plt.imshow(cv2.imread(right_image_path)[:, :, ::-1] ) # åè½¬é€šé“é¡ºåº
    plt.title('right_image')
    plt.axis('off')
    # æ˜¾ç¤ºæ·±åº¦å›¾
    plt.subplot(1, 3, 3)
    plt.imshow(depth_map, cmap='gray')
    plt.title('depth_map')
    plt.axis('off')
    # è°ƒæ•´å­å›¾é—´è·
    plt.tight_layout()
    # æ˜¾ç¤ºå›¾åƒ
    plt.show()

    # ä¿å­˜æœ€åä¸€æ¬¡è¿­ä»£çš„ç‚¹äº‘åˆ°TXTæ–‡ä»¶
    output_file_path = 'point_cloud.txt'
    save_point_cloud_to_txt(point_cloud, output_file_path)
    #save_point_cloud_to_txt_rgb(point_cloud, colors, output_file_path)
    print(f"Point cloud saved to {output_file_path}")
```


## 3ã€è¿è¡Œç»“æœ
### 3.1 å¤„ç†è€—æ—¶
```bash
Elapsed Time = 1.3469 seconds
Point cloud saved to point_cloud.txt
```
### 3.2 å·¦å›¾ã€å³å›¾å’Œè®¡ç®—çš„æ·±åº¦å›¾
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](access/013.png)
### 3.3 ä¿å­˜çš„ç‚¹äº‘æ–‡ä»¶`point_cloud.txt`
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](access/014.png)

## 4ã€ä»£ç è¯´æ˜
å‡½æ•° `compute_disparity_map` çš„åŠŸèƒ½æ˜¯**è®¡ç®—åŒç›®ç«‹ä½“è§†è§‰ä¸­çš„è§†å·®å›¾ï¼ˆDisparity Mapï¼‰**ã€‚è§†å·®å›¾æ˜¯åŒç›®ç«‹ä½“è§†è§‰ä¸­çš„å…³é”®è¾“å‡ºï¼Œå®ƒè¡¨ç¤ºå·¦å³å›¾åƒä¸­å¯¹åº”åƒç´ ç‚¹çš„æ°´å¹³ä½ç§»ï¼ˆè§†å·®ï¼‰ï¼Œå¯ä»¥ç”¨æ¥è®¡ç®—æ·±åº¦ä¿¡æ¯ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](access/015.png)


### å…·ä½“åŠŸèƒ½ï¼š
1. **è¾“å…¥**ï¼š
   - `left_image` å’Œ `right_image`ï¼šåŒç›®ç›¸æœºçš„å·¦å³å›¾åƒã€‚
   - `cam0` å’Œ `cam1`ï¼šå·¦å³ç›¸æœºçš„å†…å‚çŸ©é˜µï¼ˆè™½ç„¶å‡½æ•°ä¸­æœªç›´æ¥ä½¿ç”¨ï¼Œä½†é€šå¸¸åœ¨åç»­æ·±åº¦è®¡ç®—ä¸­ä¼šç”¨åˆ°ï¼‰ã€‚
   - `doffs`ï¼šå·¦å³ç›¸æœºå…‰å¿ƒçš„æ°´å¹³åç§»ï¼ˆé€šå¸¸ç”¨äºæ ¡æ­£åçš„å›¾åƒï¼‰ã€‚
   - `ndisp`ï¼šè§†å·®èŒƒå›´çš„æ•°é‡ï¼ˆå¿…é¡»æ˜¯ 16 çš„å€æ•°ï¼‰ã€‚
   - `vmin` å’Œ `vmax`ï¼šè§†å·®çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚
   - `block_size`ï¼šåŒ¹é…å—çš„å¤§å°ï¼ˆå¥‡æ•°ï¼‰ã€‚

2. **è¾“å‡º**ï¼š
   - `disparity_map`ï¼šè§†å·®å›¾ï¼Œè¡¨ç¤ºæ¯ä¸ªåƒç´ ç‚¹çš„è§†å·®å€¼ã€‚

3. **æ ¸å¿ƒé€»è¾‘**ï¼š
   - ä½¿ç”¨ OpenCV çš„ `cv2.StereoSGBM_create` åˆ›å»ºä¸€ä¸ªåŠå…¨å±€å—åŒ¹é…ï¼ˆSemi-Global Block Matching, SGBMï¼‰ç«‹ä½“åŒ¹é…å™¨ã€‚
   - è°ƒç”¨ `stereo.compute` è®¡ç®—å·¦å³å›¾åƒçš„è§†å·®å›¾ã€‚
   - å°†è§†å·®å›¾çš„å€¼é™¤ä»¥ 16ï¼ˆOpenCV çš„ SGBM ç®—æ³•è¿”å›çš„è§†å·®å›¾æ˜¯ 16 å€çš„å®é™…å€¼ï¼‰ã€‚

### å‚æ•°è¯¦è§£ï¼š
- **`minDisparity=vmin`**ï¼šè§†å·®çš„æœ€å°å€¼ï¼Œé€šå¸¸ä¸º 0ã€‚
- **`numDisparities=ndisp`**ï¼šè§†å·®èŒƒå›´çš„æ•°é‡ï¼Œå¿…é¡»æ˜¯ 16 çš„å€æ•°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ `ndisp=64`ï¼Œåˆ™è§†å·®èŒƒå›´ä¸º `[vmin, vmin + 64]`ã€‚
- **`blockSize=block_size`**ï¼šåŒ¹é…å—çš„å¤§å°ï¼Œå¿…é¡»æ˜¯å¥‡æ•°ã€‚è¾ƒå¤§çš„å—å¯ä»¥æé«˜é²æ£’æ€§ï¼Œä½†ä¼šé™ä½ç»†èŠ‚ã€‚
- **`P1` å’Œ `P2`**ï¼šå¹³æ»‘æƒ©ç½šé¡¹ï¼Œç”¨äºæ§åˆ¶è§†å·®å›¾çš„å¹³æ»‘ç¨‹åº¦ã€‚`P2` é€šå¸¸æ˜¯ `P1` çš„ 4 å€ã€‚
- **`disp12MaxDiff=1`**ï¼šå·¦å³è§†å·®æ£€æŸ¥çš„æœ€å¤§å…è®¸å·®å¼‚ï¼Œç”¨äºè¿‡æ»¤ä¸åŒ¹é…çš„ç‚¹ã€‚
- **`uniquenessRatio=10`**ï¼šå”¯ä¸€æ€§æ¯”ç‡é˜ˆå€¼ï¼Œç”¨äºè¿‡æ»¤éå”¯ä¸€çš„åŒ¹é…ç‚¹ã€‚
- **`speckleWindowSize=100`**ï¼šæ–‘ç‚¹æ»¤æ³¢å™¨çª—å£å¤§å°ï¼Œç”¨äºå»é™¤å°çš„å™ªå£°åŒºåŸŸã€‚
- **`speckleRange=32`**ï¼šæ–‘ç‚¹æ»¤æ³¢å™¨çš„æœ€å¤§å®¹è®¸å·®å¼‚ã€‚

### è§†å·®å›¾çš„ç”¨é€”ï¼š
è§†å·®å›¾å¯ä»¥ç”¨äºè®¡ç®—æ·±åº¦å›¾ï¼ˆDepth Mapï¼‰ï¼Œå…¬å¼ä¸ºï¼š
$$
\text{Depth} = \frac{f \cdot B}{\text{Disparity}}
$$
å…¶ä¸­ï¼š
- $f$ æ˜¯ç›¸æœºçš„ç„¦è·ï¼ˆé€šå¸¸ä»ç›¸æœºå†…å‚çŸ©é˜µä¸­è·å–ï¼‰ã€‚
- $B$ æ˜¯åŸºçº¿é•¿åº¦ï¼ˆå·¦å³ç›¸æœºå…‰å¿ƒä¹‹é—´çš„è·ç¦»ï¼‰ã€‚
- $\text{Disparity}$ æ˜¯è§†å·®å€¼ã€‚

### å‡½æ•°ä½¿ç”¨ç¤ºä¾‹ä»£ç ï¼š
```python
import cv2
import numpy as np

# å‡è®¾ left_image å’Œ right_image æ˜¯å·¦å³å›¾åƒ
left_image = cv2.imread('left.png', cv2.IMREAD_GRAYSCALE)
right_image = cv2.imread('right.png', cv2.IMREAD_GRAYSCALE)

# ç›¸æœºå†…å‚å’Œå‚æ•°
cam0 = np.array([[1000, 0, 320], [0, 1000, 240], [0, 0, 1]])  # å·¦ç›¸æœºå†…å‚
cam1 = np.array([[1000, 0, 320], [0, 1000, 240], [0, 0, 1]])  # å³ç›¸æœºå†…å‚
doffs = 0  # å…‰å¿ƒåç§»
ndisp = 64  # è§†å·®èŒƒå›´
vmin = 0  # æœ€å°è§†å·®
vmax = 64  # æœ€å¤§è§†å·®

# è®¡ç®—è§†å·®å›¾
disparity_map = compute_disparity_map(left_image, right_image, cam0, cam1, doffs, ndisp, vmin, vmax)

# æ˜¾ç¤ºè§†å·®å›¾
cv2.imshow('Disparity Map', disparity_map / ndisp)  # å½’ä¸€åŒ–æ˜¾ç¤º
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### æ³¨æ„äº‹é¡¹ï¼š
1. **å›¾åƒè¾“å…¥**ï¼šå·¦å³å›¾åƒéœ€è¦æ˜¯æ ¡æ­£åçš„å›¾åƒï¼ˆå³æçº¿å¯¹é½ï¼‰ã€‚
2. **è§†å·®èŒƒå›´**ï¼š`ndisp` çš„é€‰æ‹©éœ€è¦æ ¹æ®åœºæ™¯çš„æ·±åº¦èŒƒå›´è°ƒæ•´ã€‚
3. **æ€§èƒ½**ï¼šSGBM ç®—æ³•çš„è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œå¯¹äºé«˜åˆ†è¾¨ç‡å›¾åƒå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚

å¦‚æœæœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿è¯„è®ºï¼ğŸ˜Š







